{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Expression Recognition\n",
    "  \n",
    "## Group 3: Lingyi Cai, Yanan Li, Xiaotong Li, Yiwen Ma, Runzi Qiang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Description: In this project, we will carry out model evaluation and selection for predictive analytics on image data. As data scientists, we often need to evaluate different modeling/analysis strategies and decide what is the best. Such decisions need to be supported by sound evidence in the form of model assessment, validation and comparison. In addition, we also need to communicate our decision and supporting evidence clearly and convincingly in an accessible fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrase zero: Environment Setup\n",
    "\n",
    "- To replicate the result, please check the environment set up file to correctly set up the pytorch environment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrase one: Model Preparation\n",
    "\n",
    "- In this step, we will be doing offline data augmentation. Which includes __face detection__, __facial landmark extraction__, __face cropping__, and __width, height, shift__, __horizaontal flip__, __zooming__ and __brightness change__.\n",
    "\n",
    "- Train data folder should be under data/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xil14\\Desktop\\Zora\\Advanced Data Science\\Group3\\Group3-new\\finalize_model\n"
     ]
    }
   ],
   "source": [
    "%cd ../finalize_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following will chop the image from 750x1000 to 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "%run step0_faceCropper_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Performing face croppering, this time it will have a size of 48x48. \n",
    "\n",
    "- For detailed discussion, check [this](https://arxiv.org/pdf/1811.04544.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run step1_faceAlignment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since we are using pytorch, we are going to put the images into the format of ImageFolder. This is the conventional format of the pytorch imageFolder, for simplied, we are showing a demo from the [pytorch tutorial](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "\n",
    "        root/dog/xxx.png\n",
    "        root/dog/xxy.png\n",
    "        root/dog/xxz.png\n",
    "\n",
    "        root/cat/123.png\n",
    "        root/cat/nsdf3.png\n",
    "        root/cat/asd932_.png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run step2_subFolders.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run step3_preprocess.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrase 2: Model training.\n",
    "\n",
    "We are following the guidelines of the [github](https://github.com/WuJie1010/Facial-Expression-Recognition.Pytorch). We have experimented many architectures possible by learning multiple resources. \n",
    "\n",
    "The architecture we have experimented on are: \n",
    "\n",
    "    VGG16 \n",
    "    Resnet18\n",
    "    Resnet34\n",
    "    \n",
    "The training model provided by the following command is using Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run step5_k_fold_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The best trained model will be stored in models.folder. Now we are going to load the best model to perform prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrase 3: Model Prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model we expect is Resnet18. We pretrained by using our trained data. \n",
    "When given test data during class, we use the following command and get prediction based on that. \n",
    "\n",
    "- Please run the following command to see how the images are being classified. \n",
    "- The eventual results for the images is stored in result.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For running the test set prediction, you need to renamed the image folder to be test_images and then stored it under the .\\finalize_model\\data folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run step0_faceCropper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run step1_faceAlignment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run step7_predPrivateTest.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
